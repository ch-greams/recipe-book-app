{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Ingredients\n",
    "\n",
    "First we need to import all necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "import psycopg2\n",
    "from typing import Tuple, Any, Dict\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin, Doc\n",
    "from spacy.util import filter_spans, compile_suffix_regex, compile_infix_regex\n",
    "\n",
    "pg_connection = psycopg2.connect(\"postgresql://postgres:password@localhost\")\n",
    "pg_cursor = pg_connection.cursor()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "Doc.set_extension(\"recipe_id\", default=None, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS: list[str] = [ \"g\", \"gram\", \"cup\", \"ml\", \"kg\", \"oz\", \"tablespoon\", \"teaspoon\", \"pinch\", \"dash\", \"sprig\", \"clove\" ]\n",
    "VULGAR_FRACTIONS: list[str] = [\"¼\", \"½\", \"¾\", \"⅐\", \"⅑\", \"⅒\", \"⅓\", \"⅔\", \"⅕\", \"⅖\", \"⅗\", \"⅘\", \"⅙\", \"⅚\", \"⅛\", \"⅜\", \"⅝\", \"⅞\"]\n",
    "\n",
    "DASH_SYMBOLS: list[str] = [ \"\\u2012\", \"\\u2013\", \"\\u2014\", \"\\u2015\", \"-\" ]\n",
    "MULTIPLICATION_SYMBOLS: list[str] = [ \"x\", \"*\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Update\n",
    "\n",
    "Update `suffix_search` regex to catch all `VULGAR_FRACTIONS` and `UNITS` into separate tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_after_number_regex(suffixes: list[str]) -> str:\n",
    "    return f\"(?<=[0-9])(?:{ '|'.join(suffixes) })\"\n",
    "\n",
    "suffixes = nlp.Defaults.suffixes + [ get_after_number_regex(UNITS + VULGAR_FRACTIONS) ]\n",
    "suffix_regex = compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update `infix_finditer` regex to catch all versions of dash and `VULGAR_FRACTIONS` as infixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Adding MULTIPLICATION_SYMBOLS will cause unexpected word split\n",
    "infixes = nlp.Defaults.infixes + VULGAR_FRACTIONS + DASH_SYMBOLS\n",
    "infix_regex = compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_regex.finditer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matcher\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `RANGE_MEASURE` which will catch values like `2-3 cups` to convert them into `(2.5, cups)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"RANGE_MEASURE\", [\n",
    "    ([\n",
    "        { \"LIKE_NUM\": True, \"OP\": \"?\" },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "\n",
    "        { \"LOWER\": { \"IN\": DASH_SYMBOLS } },\n",
    "\n",
    "        { \"LIKE_NUM\": True, \"OP\": \"?\" },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "\n",
    "        { \"LEMMA\": { \"IN\": UNITS } },\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `MULTI_MEASURE` which will catch values like `2x20oz` to convert them into `(40, oz)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"MULTI_MEASURE\", [\n",
    "    ([\n",
    "        { \"LIKE_NUM\": True, \"OP\": \"?\" },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "\n",
    "        { \"LOWER\": { \"IN\": MULTIPLICATION_SYMBOLS } },\n",
    "\n",
    "        { \"LIKE_NUM\": True, \"OP\": \"?\" },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "\n",
    "        { \"LEMMA\": { \"IN\": UNITS } },\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `EXACT_MEASURE` which will catch values like `(35g)` to convert them into `(35, g)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"EXACT_MEASURE\", [\n",
    "    ([\n",
    "        { \"LOWER\": \"(\" },\n",
    "\n",
    "        { \"LIKE_NUM\": True },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "\n",
    "        { \"LEMMA\": { \"IN\": UNITS } },\n",
    "\n",
    "        { \"LOWER\": \")\" },\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `MEASURE` which will catch values like `1 kg` to convert them into `(1, kg)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"MEASURE\", [\n",
    "    ([\n",
    "        { \"LIKE_NUM\": True },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "\n",
    "        { \"LOWER\": \"heaping\", \"OP\": \"?\" },\n",
    "\n",
    "        { \"LEMMA\": { \"IN\": UNITS } },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS } },\n",
    "\n",
    "        { \"LOWER\": \"heaping\", \"OP\": \"?\" },\n",
    "\n",
    "        { \"LEMMA\": { \"IN\": UNITS } },\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `UNIT_MEASURE` which will catch values like `a cup` to convert them into `(DEFAULT_AMOUNT, cup)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"UNIT_MEASURE\", [\n",
    "    ([ { \"LEMMA\": { \"IN\": UNITS } } ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `AMOUNT_MEASURE` which will catch values like `2` to convert them into `(2, DEFAULT_UNIT)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"AMOUNT_MEASURE\", [\n",
    "    ([\n",
    "        { \"LIKE_NUM\": True },\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS }, \"OP\": \"?\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": { \"IN\": VULGAR_FRACTIONS } },\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"PRODUCT\", [\n",
    "    ([\n",
    "        { \"LOWER\": \"extra\", \"OP\": \"?\" },\n",
    "        { \"LOWER\": \"virgin\", \"OP\": \"?\" },\n",
    "        { \"LOWER\": { \"IN\": [ \"olive\", \"sesame\", \"sunflower\", \"peanut\", \"vegetable\" ] } },\n",
    "        { \"LOWER\": \"oil\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"chipotle\", \"OP\": \"?\" },\n",
    "        { \"LOWER\": { \"IN\": [ \"chilli\", \"tabasco\" ] } },\n",
    "        { \"LOWER\": \"sauce\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"sea\" },\n",
    "        { \"LOWER\": \"salt\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"black\" },\n",
    "        { \"LOWER\": \"pepper\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"unsalted\" },\n",
    "        { \"LOWER\": \"butter\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"lemon\" },\n",
    "        { \"LOWER\": \"juice\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"runny\" },\n",
    "        { \"LOWER\": \"honey\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"natural\" },\n",
    "        { \"LOWER\": \"yoghurt\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"red\" },\n",
    "        { \"LOWER\": \"wine\" },\n",
    "        { \"LOWER\": \"vinegar\" },\n",
    "    ]),\n",
    "    ([\n",
    "        { \"LOWER\": \"dried\" },\n",
    "        { \"LOWER\": \"chilli\" },\n",
    "        { \"LOWER\": \"flakes\" },\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Single Ingredient Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ents_from_match(measure: Span) -> list[Span]:\n",
    "    match measure.label_:\n",
    "        case \"EXACT_MEASURE\":\n",
    "            amount: Span = Span(measure.doc, measure.start + 1, measure.end - 2, \"AMOUNT\")\n",
    "            unit: Span = Span(measure.doc, measure.end - 2, measure.end - 1, \"UNIT\")\n",
    "            return [ amount, unit ]\n",
    "        case \"RANGE_MEASURE\" | \"MULTI_MEASURE\" | \"MEASURE\":\n",
    "            amount: Span = Span(measure.doc, measure.start, measure.end - 1, \"AMOUNT\")\n",
    "            unit: Span = Span(measure.doc, measure.end - 1, measure.end, \"UNIT\")\n",
    "            return [ amount, unit ]\n",
    "        case \"UNIT_MEASURE\":\n",
    "            unit: Span = Span(measure.doc, measure.start, measure.end, \"UNIT\")\n",
    "            return [ unit ]\n",
    "        case \"AMOUNT_MEASURE\":\n",
    "            amount: Span = Span(measure.doc, measure.start, measure.end, \"AMOUNT\")\n",
    "            return [ amount ]\n",
    "        case \"PRODUCT\":\n",
    "            product: Span = Span(measure.doc, measure.start, measure.end, \"PRODUCT\")\n",
    "            return [ product ]\n",
    "        case _:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ingredient_doc(doc: Doc, context) -> Doc:\n",
    "    doc._.recipe_id = context[\"id\"]\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "\n",
    "    non_overlapping_spans = filter_spans(spans)\n",
    "\n",
    "    # if len(non_overlapping_spans) > 1:\n",
    "    #     print(f\"recipe_id: {str(doc._.recipe_id):<8} spans: {[(sp, sp.label_) for sp in non_overlapping_spans]}\")\n",
    "\n",
    "    measures: list[Span] = []\n",
    "\n",
    "    for measure in non_overlapping_spans:\n",
    "        measures += get_ents_from_match(measure)\n",
    "\n",
    "    doc.ents = measures\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[½, -, 1, oz, fresh, red, chilli]\n"
     ]
    }
   ],
   "source": [
    "doc_temp = process_ingredient_doc(nlp(\"½-1 oz fresh red chilli\"), { \"id\": 10 })\n",
    "print([token for token in doc_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Ingredients from File\n",
    "\n",
    "Use NLTK library to identify most-popular collocations, it should be helpful to run it against ingredients were there are no amounts or units, because it usually means that something like \"salt to taste\" is used and it requires somewhat unique process in a future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "from nltk.metrics import QuadgramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import QuadgramCollocationFinder\n",
    "\n",
    "\n",
    "def get_bigram_collocations(docs: list[Doc]) -> None:\n",
    "    bigram_collocation = BigramCollocationFinder.from_documents(docs)\n",
    "    print(\"bigrams:\", bigram_collocation.nbest(BigramAssocMeasures.likelihood_ratio, 5))\n",
    "\n",
    "def get_trigram_collocations(docs: list[Doc]) -> None:\n",
    "    trigram_collocation = TrigramCollocationFinder.from_documents(docs)\n",
    "    print(\"trigrams:\", trigram_collocation.nbest(TrigramAssocMeasures.likelihood_ratio, 5))\n",
    "\n",
    "def get_quadgram_collocations(docs: list[Doc]) -> None:\n",
    "    quadgram_collocation = QuadgramCollocationFinder.from_documents(docs)\n",
    "    print(\"quadgrams:\", quadgram_collocation.nbest(QuadgramAssocMeasures.likelihood_ratio, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ingredients_from_file(ingredients: Tuple[str, Dict[str, Any]]) -> list[Doc]:\n",
    "\n",
    "    non_parsed_recipes: set[int] = set()\n",
    "    doc_count: int = 0\n",
    "    span_count: int = 0\n",
    "    empty_count: int = 0\n",
    "\n",
    "    docs: list[Doc] = []\n",
    "\n",
    "    for doc, context in nlp.pipe(ingredients, as_tuples=True):\n",
    "        doc_with_ents = process_ingredient_doc(doc, context)\n",
    "        docs.append(doc_with_ents)\n",
    "\n",
    "        if len(doc_with_ents.ents) > 0:\n",
    "            span_count += 1\n",
    "        else:\n",
    "            non_parsed_recipes.add(doc_with_ents._.recipe_id)\n",
    "            empty_count += 1\n",
    "\n",
    "        doc_count += 1\n",
    "\n",
    "    filtered_docs = list( filter(lambda doc: len(doc.ents) == 0, docs) )\n",
    "    \n",
    "\n",
    "    get_bigram_collocations( filtered_docs )\n",
    "    get_trigram_collocations( filtered_docs )\n",
    "    get_quadgram_collocations( filtered_docs )\n",
    "\n",
    "    print(f\"doc_count = {doc_count} / span_count = {span_count} / empty_count = {empty_count}\")\n",
    "    print(f\"non_parsed_recipes = {len(non_parsed_recipes)} of 2454\")\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams: [(a, bunch), (fresh, mint), (vegetables, ,), (fine, semolina), (flour, ,)]\n",
      "trigrams: [(a, bunch, of), (fresh, mint, leaves), (vegetables, ,, such), (fine, semolina, ,), (flour, ,, for)]\n",
      "quadgrams: [(a, bunch, of, fresh), (vegetables, ,, such, as), (fine, semolina, ,, for), (flour, ,, for, dusting), (higher, -, welfare, chipolata)]\n",
      "doc_count = 28001 / span_count = 27062 / empty_count = 939\n",
      "non_parsed_recipes = 939 of 2454\n"
     ]
    }
   ],
   "source": [
    "pg_cursor.execute(\"SELECT text, jsonb_build_object('recipe_id'::text, recipe_id, 'id'::text, id) FROM recipe_scraper.ingredient GROUP BY id\")\n",
    "ingredients = pg_cursor.fetchall()\n",
    "\n",
    "docs_to_save = process_ingredients_from_file(ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Training and Evaluation Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_docs_into_bin(docs: list[Doc]) -> None:\n",
    "    # doc_bin = DocBin(docs=docs)\n",
    "    # doc_bin.to_disk(\"./train.spacy\")\n",
    "\n",
    "    random.shuffle(docs)\n",
    "    train_docs = docs[:len(docs) // 2]\n",
    "    dev_docs = docs[len(docs) // 2:]\n",
    "\n",
    "    # Create and save a collection of training docs\n",
    "    train_docbin = DocBin(docs=train_docs)\n",
    "    train_docbin.to_disk(\"./docs/train.spacy\")\n",
    "    # Create and save a collection of evaluation docs\n",
    "    dev_docbin = DocBin(docs=dev_docs)\n",
    "    dev_docbin.to_disk(\"./docs/dev.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_docs_into_bin(docs_to_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('3.10.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae9fe50705d7f0848764ae5db7df823c7f326da0cf22f700d3a79878aff62703"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
