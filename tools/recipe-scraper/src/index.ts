#!/usr/bin/env node
import chalk from "chalk";
import type { OptionValues } from "commander";
import { Command, InvalidArgumentError } from "commander";
import fs from "fs";

import Logger from "./common/logger";
import { DATA_FOLDER } from "./common/utils";
import type { Recipe } from "./common/website-scraper";
import { Website } from "./common/website-scraper";
import { saveDataset, saveDatasetWithContext } from "./datasets";
import { getWebsiteScraper } from "./scrapers";



function getSupportedValues(): string {
    return Object.values(Website).join(", ");
}

function parseWebsiteEnum(value: string): Website {
    switch (value) {
        case Website.JamieOliver:
            return Website.JamieOliver;
        case Website.NYTimes:
            return Website.NYTimes;
        default:
            throw new InvalidArgumentError("Not a valid Website value.");
    }
}

//------------------------------------------------------------------------------
// recipe-scraper <command>
//------------------------------------------------------------------------------

const cli = new Command();

// Logger.log(chalk.cyan(`>>> ${process.env.npm_package_name} v${process.env.npm_package_version} <<<`));

cli.version(process.env.npm_package_version || "")
    .name("recipe-scraper")
    .description(chalk.blue("A tool for scraping recipes from websites"))
    .usage("<command>");

//------------------------------------------------------------------------------
// find-pages [options] <website>
//------------------------------------------------------------------------------

interface FindPagesOptions extends OptionValues {
    outputFolder: string;
}

cli.command("find-pages")
    .description("Traverse website and save all recipe page links")
    .argument<Website>("<website>", `name of the website to use (eg. ${getSupportedValues()})`, parseWebsiteEnum)
    .option("-o, --output-folder <path>", "path to the folder where you want to save recipe URLs", DATA_FOLDER)
    .action(async (website: Website, { outputFolder }: FindPagesOptions) => {
        Logger.info(`outputFolder: ${outputFolder}`);
        await getWebsiteScraper(website).saveRecipePages(outputFolder);
    });

//------------------------------------------------------------------------------
// scrape-recipes [options] <website>
//------------------------------------------------------------------------------

interface ScrapeRecipeOptions extends OptionValues {
    recipeUrls: string;
    offset: number;
    outputFolder: string;
    override: boolean;
    limit?: number;
}

cli.command("scrape-recipes")
    .description([
        "Scrape recipe data from provided pages.",
        "HINT: Identify website's limit and use vpn after reaching it.",
    ].join("\n"))
    .argument<Website>("<website>", `name of the website to use (eg. ${getSupportedValues()})`, parseWebsiteEnum)
    .option("-u, --recipe-urls <path>", "path to the file from where you want to get recipe URLs", `${DATA_FOLDER}/recipe_urls.json`)
    .option("--output-folder <path>", "path to the folder where you want to save recipes", DATA_FOLDER)
    .option("-o, --override", "override existing file (generated by previous run) storing recipes")
    .option<number>("-L, --limit [number]", "amount of the recipe records be file", Number)
    .option<number>("-O, --offset <number>", "starting point for recipe scraping", Number, 0)
    .action(async (website: Website, { recipeUrls, offset, outputFolder, override, limit }: ScrapeRecipeOptions) => {
        Logger.info(`recipeUrls: ${recipeUrls}, offset: ${offset}, outputFolder: ${outputFolder}, override: ${override}, limit: ${limit}`);
        const scraper = getWebsiteScraper(website);
        await scraper.scrapePages(recipeUrls, offset, outputFolder, override, limit);
    });

//------------------------------------------------------------------------------
// generate-datasets <input-file>
//------------------------------------------------------------------------------

interface GenerateDatasetsOptions extends OptionValues {
    outputFolder: string;
    context: boolean;
    json: boolean;
}

cli.command("generate-datasets")
    .description("Generate ingredients and instructions datasets from provided recipes.")
    .argument("<input-file>", "path to the file from where you want to get recipes")
    .option("-o, --output-folder <path>", "path to the folder where you want to save recipe URLs", DATA_FOLDER)
    .option("-c, --context", "attach default context to datasets")
    .option("-j, --json", "save produced datasets in json format (by default csv will be used)")
    .action(async (inputFile, { outputFolder, context, json }: GenerateDatasetsOptions) => {
        const format = json ? "json" : "csv";

        Logger.info(`inputFile: ${inputFile}, outputFolder: ${outputFolder}, format: ${format}`);

        const recipes: Recipe[] = JSON.parse(fs.readFileSync(inputFile, { encoding: "utf8" }));

        if (context) {

            saveDatasetWithContext("ingredients", recipes, outputFolder, format);

            saveDatasetWithContext("instructions", recipes, outputFolder, format);

            saveDatasetWithContext("tags", recipes, outputFolder, format);
        }
        else {

            saveDataset("ingredients", recipes, outputFolder, format);

            saveDataset("instructions", recipes, outputFolder, format);

            saveDataset("tags", recipes, outputFolder, format);
        }
    });

//------------------------------------------------------------------------------

cli.parse(process.argv);

